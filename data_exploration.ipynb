{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45fb5ef-f1bd-4f83-8432-4c9129fe761e",
   "metadata": {},
   "source": [
    "# Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fbb7e3-ae7b-4e9e-b5bd-f751a0c2083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import MotionClass, Marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cacb2a-e3e4-4c89-87ac-9f2f9c4fe7aa",
   "metadata": {},
   "source": [
    "The motion classes used in this task are:\n",
    "\n",
    "- **Centering** the clay.\n",
    "- **Making a hole** in the clay.\n",
    "- **Pressing** the clay to make it stick to the pottery wheel.\n",
    "- **Raising** the base structure of the clay\n",
    "- **Smoothing** the walls\n",
    "- Using the **sponge** to make the clay more moist.\n",
    "- **Tightening** the cylinder of the clay.\n",
    "\n",
    "They are represented in the code as members of the *MotionClass enum* with values representing their index in alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998edb4a-62f4-4fcc-abe5-b0369439636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<MotionClass.Centering: 0>, <MotionClass.MakingHole: 1>, <MotionClass.Pressing: 2>, <MotionClass.Raising: 3>, <MotionClass.Smoothing: 4>, <MotionClass.Sponge: 5>, <MotionClass.Tightening: 6>]\n"
     ]
    }
   ],
   "source": [
    "print(list(MotionClass))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109703c-34ca-434c-bad8-de5f8b5095e9",
   "metadata": {},
   "source": [
    "Hand motions were captured using a Vicon System containing 14 Vantage Cameras that tracked reflective markers on the subject's hands.\n",
    "\n",
    "The different markers are represented in the code as members of the *Marker enum* with values representing their order of appearance in the structure of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7190ba76-bc63-4320-8372-deb06857e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Marker.LIWR: 0>, <Marker.LOWR: 1>, <Marker.LIHAND: 2>, <Marker.LOHAND: 3>, <Marker.LTHM3: 4>, <Marker.LTHM6: 5>, <Marker.LIDX3: 6>, <Marker.LIDX6: 7>, <Marker.LMID0: 8>, <Marker.LMID6: 9>, <Marker.LRNG3: 10>, <Marker.LRNG6: 11>, <Marker.LPNK3: 12>, <Marker.LPNK6: 13>, <Marker.RIWR: 14>, <Marker.ROWR: 15>, <Marker.RIHAND: 16>, <Marker.ROHAND: 17>, <Marker.RTHM3: 18>, <Marker.RTHM6: 19>, <Marker.RIDX3: 20>, <Marker.RIDX6: 21>, <Marker.RMID0: 22>, <Marker.RMID6: 23>, <Marker.RRNG3: 24>, <Marker.RRNG6: 25>, <Marker.RPNK3: 26>, <Marker.RPNK6: 27>]\n"
     ]
    }
   ],
   "source": [
    "print([m for m in Marker])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214ae0c-895c-447d-8c6b-dd0a95a1d102",
   "metadata": {},
   "source": [
    "Some arbitrary connections between the different markers were also defined to act as edges during data visualization as shown in the figure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a1b76f-84df-499c-a342-464007388691",
   "metadata": {},
   "source": [
    "![Sensor Map](img/sensors_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64372a7-ccb9-4603-85e8-ca09e87e71d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 4), (4, 5), (0, 2), (2, 6), (6, 7), (2, 8), (8, 9), (8, 3), (2, 3), (3, 10), (10, 11), (3, 12), (12, 13), (3, 1), (14, 15), (14, 18), (18, 19), (14, 16), (16, 20), (20, 21), (16, 22), (22, 23), (22, 17), (16, 17), (17, 24), (24, 25), (17, 26), (26, 27), (17, 15)]\n"
     ]
    }
   ],
   "source": [
    "print(Marker.connections(index_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0853a-0af7-4a20-8a72-79e79706cc2b",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb1ae51-a4cb-4d6c-a421-6c19c8cef23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import DataParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276d1bf-3e2b-4852-9f61-185d9ebcc13f",
   "metadata": {},
   "source": [
    "The provided data can be parsed using the *DataParser* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8eef12-6dd2-4326-9147-8ce78c74edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataParser(\"Data Split/Train-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3674a34c-5b76-4831-90c7-e3090a4cffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file Data Split/Train-set/Centering/01.txt\n",
      "reading file Data Split/Train-set/Centering/02.txt\n",
      "reading file Data Split/Train-set/Centering/03.txt\n",
      "reading file Data Split/Train-set/Centering/04.txt\n",
      "reading file Data Split/Train-set/Centering/05.txt\n",
      "reading file Data Split/Train-set/Centering/06.txt\n",
      "reading file Data Split/Train-set/Centering/07.txt\n",
      "reading file Data Split/Train-set/Centering/08.txt\n",
      "reading file Data Split/Train-set/Centering/09.txt\n",
      "reading file Data Split/Train-set/Centering/10.txt\n",
      "reading file Data Split/Train-set/Centering/11.txt\n",
      "reading file Data Split/Train-set/Centering/12.txt\n",
      "reading file Data Split/Train-set/Centering/13.txt\n",
      "reading file Data Split/Train-set/MakingHole/01.txt\n",
      "reading file Data Split/Train-set/MakingHole/02.txt\n",
      "reading file Data Split/Train-set/MakingHole/03.txt\n",
      "reading file Data Split/Train-set/MakingHole/04.txt\n",
      "reading file Data Split/Train-set/Pressing/01.txt\n",
      "reading file Data Split/Train-set/Pressing/02.txt\n",
      "reading file Data Split/Train-set/Pressing/03.txt\n",
      "reading file Data Split/Train-set/Pressing/04.txt\n",
      "reading file Data Split/Train-set/Pressing/05.txt\n",
      "reading file Data Split/Train-set/Pressing/06.txt\n",
      "reading file Data Split/Train-set/Pressing/07.txt\n",
      "reading file Data Split/Train-set/Pressing/08.txt\n",
      "reading file Data Split/Train-set/Raising/01.txt\n",
      "reading file Data Split/Train-set/Raising/02.txt\n",
      "reading file Data Split/Train-set/Raising/03.txt\n",
      "reading file Data Split/Train-set/Raising/04.txt\n",
      "reading file Data Split/Train-set/Raising/05.txt\n",
      "reading file Data Split/Train-set/Raising/06.txt\n",
      "reading file Data Split/Train-set/Raising/07.txt\n",
      "reading file Data Split/Train-set/Raising/08.txt\n",
      "reading file Data Split/Train-set/Smoothing/01.txt\n",
      "reading file Data Split/Train-set/Smoothing/02.txt\n",
      "reading file Data Split/Train-set/Smoothing/03.txt\n",
      "reading file Data Split/Train-set/Smoothing/04.txt\n",
      "reading file Data Split/Train-set/Smoothing/05.txt\n",
      "reading file Data Split/Train-set/Smoothing/06.txt\n",
      "reading file Data Split/Train-set/Smoothing/07.txt\n",
      "reading file Data Split/Train-set/Sponge/01.txt\n",
      "reading file Data Split/Train-set/Sponge/02.txt\n",
      "reading file Data Split/Train-set/Sponge/03.txt\n",
      "reading file Data Split/Train-set/Sponge/04.txt\n",
      "reading file Data Split/Train-set/Sponge/05.txt\n",
      "reading file Data Split/Train-set/Sponge/06.txt\n",
      "reading file Data Split/Train-set/Tightening/01.txt\n",
      "reading file Data Split/Train-set/Tightening/02.txt\n",
      "reading file Data Split/Train-set/Tightening/03.txt\n",
      "reading file Data Split/Train-set/Tightening/04.txt\n"
     ]
    }
   ],
   "source": [
    "data = dp.parse(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a4b2f-9e3a-48a8-92d0-1cc22aae6cbc",
   "metadata": {},
   "source": [
    "The resulting *Data* object is a collection of *MotionCapture* objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72a63f9-63f4-4fb9-bfa5-229b5c53c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Centering (13 examples),\n",
      " MakingHole (4 examples),\n",
      " Pressing (8 examples),\n",
      " Raising (8 examples),\n",
      " Smoothing (7 examples),\n",
      " Sponge (6 examples),\n",
      " Tightening (4 examples)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33d419-14ef-44ae-944e-5f014b30db60",
   "metadata": {},
   "source": [
    "It can be indexed based on the different MotionClasses, e.g. to get all available motion captures of class Centering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d698178-50d8-46c9-9c43-d1f662da4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "centering_data = data['Centering'] # or centering_data = data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba78f9-d2bf-412d-b722-711e7cb23f46",
   "metadata": {},
   "source": [
    "Each *MotionCapture* object is a collection of *DataPoint* objects (frames):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906e70d9-7ca2-4dc6-a365-ea95d3a7a6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 695\n",
      "1 2003\n",
      "2 1662\n",
      "3 2805\n",
      "4 542\n",
      "5 2031\n",
      "6 973\n",
      "7 945\n",
      "8 1855\n",
      "9 555\n",
      "10 788\n",
      "11 972\n",
      "12 1078\n"
     ]
    }
   ],
   "source": [
    "for idx, mocap in enumerate(centering_data):\n",
    "    # number of datapoints (frames) per mocap\n",
    "    print(idx, len(mocap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f777e1-7a1f-459f-bc0d-548e7c2a1190",
   "metadata": {},
   "source": [
    "Each *DataPoint* object is in turn a collection of (Marker, Position) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79aac55d-5be0-41af-8882-00b278dc35b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {<Marker.LIWR: 0>: (0.7500197291374207, -120.93955993652344, 64.11278533935547), <Marker.LOWR: 1>: (0.6362690329551697, -114.785888671875, 59.901371002197266), <Marker.LIHAND: 2>: (3.687148094177246, -111.3758544921875, 65.29667663574219), <Marker.LOHAND: 3>: (1.8990695476531982, -111.50431060791016, 59.817020416259766), <Marker.LTHM3: 4>: (6.849764347076416, -116.37320709228516, 68.35850524902344), <Marker.LTHM6: 5>: (8.995986938476562, -114.20111083984375, 70.23192596435547), <Marker.LIDX3: 6>: (9.025297164916992, -106.94117736816406, 64.58393859863281), <Marker.LIDX6: 7>: (11.819718360900879, -106.34879302978516, 62.93034744262695), <Marker.LMID0: 8>: (4.978232383728027, -108.43028259277344, 62.856197357177734), <Marker.LMID6: 9>: (11.740866661071777, -105.47238159179688, 60.69208526611328), <Marker.LRNG3: 10>: (7.830949306488037, -106.44918060302734, 59.58268737792969), <Marker.LRNG6: 11>: (10.922754287719727, -105.85246276855469, 58.63535690307617), <Marker.LPNK3: 12>: (5.92537260055542, -108.3884506225586, 58.18885803222656), <Marker.LPNK6: 13>: (7.934599876403809, -107.40315246582031, 57.53550720214844), <Marker.RIWR: 14>: (20.306867599487305, -125.87713623046875, 63.97600173950195), <Marker.ROWR: 15>: (24.435596466064453, -122.97189331054688, 59.28810119628906), <Marker.RIHAND: 16>: (19.56095314025879, -119.58329772949219, 67.25621032714844), <Marker.ROHAND: 17>: (22.635478973388672, -117.83680725097656, 64.59801483154297), <Marker.RTHM3: 18>: (13.71357536315918, -120.86094665527344, 67.65316009521484), <Marker.RTHM6: 19>: (12.054136276245117, -119.87267303466797, 69.29947662353516), <Marker.RIDX3: 20>: (15.811372756958008, -111.95392608642578, 68.08475494384766), <Marker.RIDX6: 21>: (14.99514102935791, -110.03801727294922, 65.87226867675781), <Marker.RMID0: 22>: (19.66311264038086, -114.73675537109375, 67.5787124633789), <Marker.RMID6: 23>: (15.922481536865234, -108.52684020996094, 64.69770812988281), <Marker.RRNG3: 24>: (19.225839614868164, -110.50531005859375, 65.33109283447266), <Marker.RRNG6: 25>: (16.880949020385742, -108.73480987548828, 63.21030807495117), <Marker.RPNK3: 26>: (21.16663932800293, -112.76539611816406, 63.94650650024414), <Marker.RPNK6: 27>: (18.416702270507812, -109.39112854003906, 61.89604187011719)}\n"
     ]
    }
   ],
   "source": [
    "centering_example = centering_data[0]\n",
    "print(centering_example[0]) # first data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae20f727-19ab-42af-9361-41298ab5d00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7500197291374207, -120.93955993652344, 64.11278533935547)\n",
      "(0.7454673051834106, -120.9395751953125, 64.11933135986328)\n",
      "(0.7381309866905212, -120.938232421875, 64.11846160888672)\n",
      "(0.7309368252754211, -120.93473052978516, 64.10693359375)\n",
      "(0.7318063378334045, -120.93157196044922, 64.10041046142578)\n",
      "(0.7406777143478394, -120.92839813232422, 64.1033935546875)\n",
      "(0.7516973614692688, -120.92552185058594, 64.10018920898438)\n",
      "(0.7593153715133667, -120.9196548461914, 64.08901977539062)\n",
      "(0.7700400352478027, -120.91438293457031, 64.07542419433594)\n",
      "(0.7889735102653503, -120.91321563720703, 64.0657730102539)\n"
     ]
    }
   ],
   "source": [
    "# movement of sensor LIWR\n",
    "liwr = [datapoint['LIWR'] for datapoint in centering_example]\n",
    "print(\"\\n\".join([str(x) for x in liwr[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfe691-7ce0-4074-b44c-bc409905ad6d",
   "metadata": {},
   "source": [
    "Indexing and slicing of the different datatypes is robust and as Pythonic as possible. This allows us to perform complex operations very elegantly.\n",
    "\n",
    "For example to keep every 50th frame and downsample a mocap, standard slicing syntax can be used directly on the *MotionCapture* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87871f51-dcd9-4fdc-8ba2-ff4488507b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<data.DataPoint at 0x7f70e289ff50>,\n",
       " <data.DataPoint at 0x7f70e06ff110>,\n",
       " <data.DataPoint at 0x7f70e2803b50>,\n",
       " <data.DataPoint at 0x7f70e0770590>,\n",
       " <data.DataPoint at 0x7f70e05aca50>,\n",
       " <data.DataPoint at 0x7f70e05e8f50>,\n",
       " <data.DataPoint at 0x7f70e06214d0>,\n",
       " <data.DataPoint at 0x7f70e0659a10>,\n",
       " <data.DataPoint at 0x7f70e0691ed0>,\n",
       " <data.DataPoint at 0x7f70e04ce350>,\n",
       " <data.DataPoint at 0x7f70e050a8d0>,\n",
       " <data.DataPoint at 0x7f70e0542d50>,\n",
       " <data.DataPoint at 0x7f70e057b310>,\n",
       " <data.DataPoint at 0x7f70e03b7690>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample mocap\n",
    "centering_example[::50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9ccca-dd7b-4564-9513-bb56bf72aeb7",
   "metadata": {},
   "source": [
    "The ability to drop (or keep) specific marker data is also provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6854c6c1-eed3-4bda-9797-9b9b3e0d4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: {<Marker.LTHM6: 5>: (8.995986938476562, -114.20111083984375, 70.23192596435547), <Marker.LIDX6: 7>: (11.819718360900879, -106.34879302978516, 62.93034744262695), <Marker.LMID6: 9>: (11.740866661071777, -105.47238159179688, 60.69208526611328), <Marker.LRNG6: 11>: (10.922754287719727, -105.85246276855469, 58.63535690307617), <Marker.LPNK6: 13>: (7.934599876403809, -107.40315246582031, 57.53550720214844), <Marker.RTHM6: 19>: (12.054136276245117, -119.87267303466797, 69.29947662353516), <Marker.RIDX6: 21>: (14.99514102935791, -110.03801727294922, 65.87226867675781), <Marker.RMID6: 23>: (15.922481536865234, -108.52684020996094, 64.69770812988281), <Marker.RRNG6: 25>: (16.880949020385742, -108.73480987548828, 63.21030807495117), <Marker.RPNK6: 27>: (18.416702270507812, -109.39112854003906, 61.89604187011719)}\n"
     ]
    }
   ],
   "source": [
    "finger_data = data.filter_markers([5, 7, 9, 11, 13, 19, 21, 23, 25, 27], keep=True) # keep only fingertip marker data\n",
    "print(finger_data[0][0][0]) # first frame of first example of first class (centering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d621b0e8-ae90-462c-9f89-41549e134156",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc06ece-1e22-450d-a050-fef5a38642b8",
   "metadata": {},
   "source": [
    "Finally both datapoints and entire mocaps can be visualized using open3d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a309c8-271c-4b3a-abed-7c3470510355",
   "metadata": {},
   "source": [
    "## Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e56710-ee32-4819-b27d-c5e5f1f29149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from visualize import HandVisualizer, MocapVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17afbbe6-3100-435d-9bff-320d34f2d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = centering_example[0] # first frame of first centering example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "636fd532-47c5-468e-8004-6fd26aad6774",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = HandVisualizer(datapoint)\n",
    "hands.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e806b-aefd-40e4-8879-19bc1d786249",
   "metadata": {},
   "source": [
    "## Animated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca730e6-39e3-48df-8c90-9e2fef9b654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mocap = data['Sponge'][0] # entire centering example\n",
    "len(mocap) # number of frames (datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aea0de5-fe7e-4f29-b49c-28e27964a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = MocapVisualizer(mocap)\n",
    "viz.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shrec",
   "language": "python",
   "name": "shrec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
